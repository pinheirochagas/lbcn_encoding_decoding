{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pinheirochagas/anaconda3/envs/mne/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/Users/pinheirochagas/anaconda3/envs/mne/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import pandas as pd\n",
    "from modelingtools import delay_time_series, plot_activity_on_brain\n",
    "from modelingtools import (plot_cv_indices, cross_validate_alpha)\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression, LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, scale\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.learning_curve import learning_curve\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, r2_score\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.collections as clt\n",
    "import ptitprince as pt\n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "from sklearn import cross_validation as cv\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import list of subjects\n",
    "s_list = pd.read_csv('/Volumes/LBCN8T_2/Stanford/data/encoding/subject_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_list.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0e1867aca279>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Import list of subjects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m## Stim features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Volumes/LBCN8T_2/Stanford/data/encoding/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_stim_features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's_list' is not defined"
     ]
    }
   ],
   "source": [
    "## Import list of subjects\n",
    "for si in range(0,s_list.shape[0]):\n",
    "    ## Stim features\n",
    "    data = pd.read_csv('/Volumes/LBCN8T_2/Stanford/data/encoding/' + str(s_list['name'][si]) + '_stim_features.csv')\n",
    "    data.head()\n",
    "\n",
    "    ## Recode task name\n",
    "    data.loc[data.loc[:,'task_general_cond_name']==4, 'task_general_cond_name'] = 2\n",
    "    data.loc[data.loc[:,'task_general_cond_name']==6, 'task_general_cond_name'] = 1\n",
    "\n",
    "    ## Brain features\n",
    "    # Set extreme values to zero (double check spike exclusion)\n",
    "    #data = np.genfromtxt('/Volumes/LBCN8T_2/Stanford/data/encoding/57_brain_features.csv', delimiter=',')\n",
    "    #data.loc[data.loc[:,'HFB']>30, 'HFB'] = 0\n",
    "    y_tmp = pd.read_csv('/Volumes/LBCN8T_2/Stanford/data/encoding/' + str(s_list['name'][si]) + '_brain_features.csv', header=None)\n",
    "    y = y_tmp.to_numpy()\n",
    "    y[y>30]=0 # Set extreme values to 0\n",
    "    ## log transform y\n",
    "    #y = np.log(np.abs(y+1))   \n",
    "    #y[np.isinf(y)] = 0\n",
    "    # Filter trials\n",
    "    good_trials = (data.loc[:,'task_general_cond_name'] == 1) | (data.loc[:,'task_general_cond_name'] == 2)\n",
    "    y = y[good_trials,:]\n",
    "    data = data.loc[good_trials,:]\n",
    "\n",
    "    # Define trials\n",
    "    times = np.shape(np.unique(data.loc[:,'time']))\n",
    "    times = int(times[0])\n",
    "    r,c = np.shape(data)\n",
    "    trials = int(r/times)\n",
    "    trials_rs = np.matlib.repmat(np.arange(1,trials+1),times,1).T\n",
    "    trials_rs = trials_rs.reshape(-1,1)\n",
    "    data['trials'] = trials_rs\n",
    "\n",
    "    # Select features\n",
    "    features = np.array(data.loc[:,'task_general_cond_name'])\n",
    "\n",
    "    # Reshape features\n",
    "    features_reshape = np.reshape(features, (trials, times))\n",
    "    features_reshape = np.expand_dims(features_reshape, axis=1)\n",
    "\n",
    "    # Add delayed features\n",
    "    fs = 500\n",
    "    time_window = 0.02;\n",
    "    #n_delays = 100\n",
    "    #delays = np.linspace(1, 2, 100)\n",
    "\n",
    "    start = 0; stop = 2; step = time_window\n",
    "    delays = np.arange(start, stop+step, step)\n",
    "    n_delays = int(len(delays))\n",
    "\n",
    "    X_delayed = np.zeros((trials,1,n_delays,times))\n",
    "    for i in range(trials):\n",
    "        for ii in range(n_delays):\n",
    "            window = [int(np.round(delays[ii]*fs)),int(np.round((delays[ii]+time_window)*fs))]\n",
    "            X_delayed[i,0,ii,window[0]:window[1]] = int(np.unique(features_reshape[i]))\n",
    "\n",
    "    # Concatenate back the delayed features\n",
    "    X_env = X_delayed.reshape([X_delayed.shape[0], -1, X_delayed.shape[-1]])\n",
    "    X = np.hstack(X_env).T\n",
    "\n",
    "    # We'll use the KFold iterator, shuffling trial numbers first\n",
    "    cross_val_iterator = cv.KFold(trials, n_folds=10, shuffle=True)\n",
    "    model = Ridge(alpha=1e5)\n",
    "\n",
    "\n",
    "    fig, axs = plt.subplots(len(cross_val_iterator), 1,\n",
    "                            figsize=(10, 5*len(cross_val_iterator)),\n",
    "                            sharex=True)\n",
    "    axs[0].set_title('Predicted and Actual High-Frequency Activity')\n",
    "    axs[1].set_ylabel('Amplitude (a.u.)')\n",
    "    axs[-1].set_xlabel('Time (s)')\n",
    "\n",
    "    scores_all = np.zeros([y.shape[1], cross_val_iterator.n_folds])\n",
    "    coefs_all = np.zeros([y.shape[1], X.shape[1], cross_val_iterator.n_folds])\n",
    "    intercept_all = np.zeros([y.shape[1], cross_val_iterator.n_folds])\n",
    "\n",
    "    scores_cv = np.zeros(y.shape[1])\n",
    "\n",
    "    counter = 0\n",
    "    for ax, (tr, tt) in zip(axs, cross_val_iterator):\n",
    "        # Pull the training / testing data for the ecog data\n",
    "        y_tr = y[data['trials'].isin(tr)]\n",
    "        y_tt = y[data['trials'].isin(tt)]\n",
    "\n",
    "        # Pull the training / testing data for the spectrogram\n",
    "        X_tr = X[data['trials'].isin(tr)]\n",
    "        X_tt = X[data['trials'].isin(tt)]\n",
    "\n",
    "        # Scale all the features for simplicity\n",
    "        X_tr = scale(X_tr)\n",
    "        X_tt = scale(X_tt)\n",
    "        y_tr = scale(y_tr)\n",
    "        y_tt = scale(y_tt)\n",
    "\n",
    "        # Fit the model, and use it to predict on new data\n",
    "        model.fit(X_tr, y_tr)\n",
    "        predictions = model.predict(X_tt)\n",
    "\n",
    "        # Get the average (R2)\n",
    "        # Get the average (R2)\n",
    "        for i in range(0, y.shape[1]):\n",
    "            scores_cv[i] = r2_score(y_tt[:,i], predictions[:,i])\n",
    "\n",
    "        scores_all[:,counter] = scores_cv\n",
    "        coefs_all[:,:,counter] = model.coef_\n",
    "        intercept_all[:,counter] = model.intercept_\n",
    "        counter = counter + 1\n",
    "\n",
    "    scores_all = np.mean(scores_all, axis=1)\n",
    "    coefs_all = np.mean(coefs_all, axis=2)\n",
    "    intercept_all = np.mean(intercept_all, axis=1)\n",
    "    #np.savetxt('/Volumes/LBCN8T_2/Stanford/data/encoding/' + str(s_list['name'][si]) + '_scores.csv', scores_all, delimiter=',')\n",
    "    np.savetxt('/Volumes/LBCN8T_2/Stanford/data/encoding/' + str(s_list['name'][si]) + '_scores.csv', scores_all, delimiter=',')\n",
    "    np.savetxt('/Volumes/LBCN8T_2/Stanford/data/encoding/' + str(s_list['name'][si]) + '_coefs.csv', coefs_all, delimiter=',')\n",
    "    np.savetxt('/Volumes/LBCN8T_2/Stanford/data/encoding/' + str(s_list['name'][si]) + '_intercept.csv', intercept_all, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.intercept_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs_all = np.zeros([y.shape[1], X.shape[1], cross_val_iterator.n_folds])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 76, 10)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs_all.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'si' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b53c756d181a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'si' is not defined"
     ]
    }
   ],
   "source": [
    "si"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
